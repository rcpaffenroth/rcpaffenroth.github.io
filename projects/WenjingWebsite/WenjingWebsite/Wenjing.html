<!DOCTYPE html>
<html>
<body>

<h1>Wenjing Li<img src="Wenjing_Li.png" height="75" align="left"></h1>

<h3>Mathematical Department PHD Student 
</h3>

<h3><left>Large Scale Ensemble Learning <br></left></h3>

<p>  </p>
<p><img src="ensemble_learning.png" height="250" width="250"align="right">Ensemble learning is a very important technic in machine learning, and it is also widely used in industrial field because of the good performance on predictions and classifications. However, the reason why it works so good is rarely understood. This project aims to figure out the mysterious parts of ensemble learning and even develop some theorems that support ensemble learning. Generally speaking, ensemble learning is a process by which multiple models, such as classifiers or experts, are strategically generated and combined to produce a better algorithm. It is primarily used to improve the classification or prediction performance of a model, or to reduce the risk of selecting a poor model. Therefore, there are two major focuses of ensemble learning: the first one is the process of model generation and selection, and the other one is the model combining strategy.
</p>

<h3><left>Publications:</left></h3>
<A href="Wenjing_Paper1Title.pdf">Click Here for Paper</A>


</body>
</html>